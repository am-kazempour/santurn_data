{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4011fc16-ce08-41c5-bdac-486b9140f17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:06.659719Z",
     "iopub.status.busy": "2023-11-28T17:38:06.659417Z",
     "iopub.status.idle": "2023-11-28T17:38:09.710660Z",
     "shell.execute_reply": "2023-11-28T17:38:09.710026Z",
     "shell.execute_reply.started": "2023-11-28T17:38:06.659697Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-11-28 17:38:08.204824: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 17:38:08.247089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 17:38:08.247118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 17:38:08.248273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-28 17:38:08.254762: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 17:38:08.255638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 17:38:09.075409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout, Embedding,LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fad341d-3ebd-4e94-88ae-49ab4e02bd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:13.203835Z",
     "iopub.status.busy": "2023-11-28T17:38:13.203437Z",
     "iopub.status.idle": "2023-11-28T17:38:13.242096Z",
     "shell.execute_reply": "2023-11-28T17:38:13.241548Z",
     "shell.execute_reply.started": "2023-11-28T17:38:13.203811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3003ee23-179b-4f1f-b220-aa5b38479e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:15.733111Z",
     "iopub.status.busy": "2023-11-28T17:38:15.732683Z",
     "iopub.status.idle": "2023-11-28T17:38:15.841902Z",
     "shell.execute_reply": "2023-11-28T17:38:15.841317Z",
     "shell.execute_reply.started": "2023-11-28T17:38:15.733087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/semeval-2017-train.csv\", on_bad_lines=\"skip\", sep=\"\\t\")\n",
    "df_t = pd.read_csv(\"dataset/semeval-2017-test.csv\", on_bad_lines=\"skip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82be775a-2760-479f-ab85-6c50c91081e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:17.847316Z",
     "iopub.status.busy": "2023-11-28T17:38:17.846913Z",
     "iopub.status.idle": "2023-11-28T17:38:17.851808Z",
     "shell.execute_reply": "2023-11-28T17:38:17.851160Z",
     "shell.execute_reply.started": "2023-11-28T17:38:17.847292Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # Tokenization (you can customize this based on your needs)\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd6c78d-194f-4658-9d80-bce2775dde21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:24.775348Z",
     "iopub.status.busy": "2023-11-28T17:38:24.774953Z",
     "iopub.status.idle": "2023-11-28T17:38:30.849982Z",
     "shell.execute_reply": "2023-11-28T17:38:30.849388Z",
     "shell.execute_reply.started": "2023-11-28T17:38:24.775325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the comments\n",
    "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
    "df_t[\"processed_text\"] = df_t[\"text\"].apply(preprocess_text)\n",
    "df['label'] = df['label'].replace({0:1})\n",
    "df_t['label'] = df_t['label'].replace({0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbb4bec-d653-4ae4-b516-cb98cdaeea5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:38:34.675481Z",
     "iopub.status.busy": "2023-11-28T17:38:34.675087Z",
     "iopub.status.idle": "2023-11-28T17:38:36.126392Z",
     "shell.execute_reply": "2023-11-28T17:38:36.125658Z",
     "shell.execute_reply.started": "2023-11-28T17:38:34.675456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "texts = df[\"processed_text\"]\n",
    "labels = np.array(df[\"label\"])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "embedding_dim = 100\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6223eb5e-d198-48af-8210-10842fae778e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T18:30:07.585679Z",
     "iopub.status.busy": "2023-11-28T18:30:07.585286Z",
     "iopub.status.idle": "2023-11-28T18:35:50.330280Z",
     "shell.execute_reply": "2023-11-28T18:35:50.329697Z",
     "shell.execute_reply.started": "2023-11-28T18:30:07.585657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6933 - accuracy: 0.4222\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6881 - accuracy: 0.7484\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6821 - accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6738 - accuracy: 0.8549\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6632 - accuracy: 0.8558\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6479 - accuracy: 0.8558\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6235 - accuracy: 0.8558\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5996 - accuracy: 0.8558\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6591 - accuracy: 0.8558\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6178 - accuracy: 0.8558\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6207 - accuracy: 0.8446\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6197 - accuracy: 0.8446\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6206 - accuracy: 0.8446\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6228 - accuracy: 0.8446\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6232 - accuracy: 0.8446\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6211 - accuracy: 0.8446\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6165 - accuracy: 0.8446\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6123 - accuracy: 0.8446\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6060 - accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5988 - accuracy: 0.8446\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6005 - accuracy: 0.8527\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5930 - accuracy: 0.8527\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5857 - accuracy: 0.8527\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5795 - accuracy: 0.8527\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5747 - accuracy: 0.8527\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5747 - accuracy: 0.8527\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5662 - accuracy: 0.8527\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5549 - accuracy: 0.8527\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5435 - accuracy: 0.8527\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5305 - accuracy: 0.8525\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5837 - accuracy: 0.8342\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5753 - accuracy: 0.8338\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5642 - accuracy: 0.8326\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5538 - accuracy: 0.8296\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5412 - accuracy: 0.8252\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5241 - accuracy: 0.8196\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5065 - accuracy: 0.8143\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4876 - accuracy: 0.8078\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4614 - accuracy: 0.8027\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4343 - accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "# model.add(GRU(128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = []\n",
    "# Training\n",
    "step = 12000\n",
    "for i in range(0, 48000, step):\n",
    "    h = model.fit(padded_sequences[i:i + step], labels[i:i + step], batch_size=len(padded_sequences[i:i + step]), epochs=10)\n",
    "    history += h.history['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d354af84-3e65-4971-9423-98372990be45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T18:36:07.741875Z",
     "iopub.status.busy": "2023-11-28T18:36:07.741488Z",
     "iopub.status.idle": "2023-11-28T18:36:23.857747Z",
     "shell.execute_reply": "2023-11-28T18:36:23.856999Z",
     "shell.execute_reply.started": "2023-11-28T18:36:07.741849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 16s 41ms/step\n",
      "[[0.45613053]\n",
      " [0.40381715]\n",
      " [0.4670435 ]\n",
      " ...\n",
      " [0.8282494 ]\n",
      " [0.69376713]\n",
      " [0.83340305]]\n"
     ]
    }
   ],
   "source": [
    "# model.fit(padded_sequences[45000:49000], labels[45000:49000], batch_size=len(padded_sequences[45000:49000]), epochs=10)\n",
    "# Testing\n",
    "test_texts = df_t['processed_text']\n",
    "true_labels = np.array(df_t['label'])\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=max_length)\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0e2a016-88e7-4057-ba27-d419039638ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T18:36:59.288853Z",
     "iopub.status.busy": "2023-11-28T18:36:59.288487Z",
     "iopub.status.idle": "2023-11-28T18:36:59.431837Z",
     "shell.execute_reply": "2023-11-28T18:36:59.431032Z",
     "shell.execute_reply.started": "2023-11-28T18:36:59.288828Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207147031810971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "binary_predictions = [1 if (p[0]) > 0.5 else -1 for p in predictions]\n",
    "acc = accuracy_score(true_labels, binary_predictions)\n",
    "print(acc)\n",
    "model.save('7207.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
